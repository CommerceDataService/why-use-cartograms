{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Census stats for each U.S. Census Tract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First, we import packages needed to fetch Census statistics for each U.S. Census Tract. A combination of:\n",
    "* sys, \n",
    "* os, \n",
    "* json, \n",
    "* io, \n",
    "* urllib.request, \n",
    "* and csv\n",
    "is used to both process the Census API call and ultimately output to csv.\n",
    "\n",
    "*nb. There is no tract data for American Samoa (FIPS 60), Guam (FIPS 66), Northern Mariana Islands (FIPS 69), and Virgin Islands (FIPS 78)? So I'm skipping those state-equivalents from analysis.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os, json, io, urllib.request, csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we declare variables needed prior to the actual call to the Census API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2010-2014 American Community Survey 5-Year Estimates\n",
    "dataset = \"http://api.census.gov/data/2014/acs5\"\n",
    "\n",
    "api_key = os.environ[\"API_KEY\"]\n",
    "unit = sys.argv[1] # \"tract\" or \"county\"\n",
    "\n",
    "fields = {\n",
    "\t\"B01003_001E\": \"population\",\n",
    "\t\"B02001_002E\": \"white\", # white alone\n",
    "\t\n",
    "  \"B19013_001E\": \"median_income\", # Median Household Income in the Past 12 Months (in 2014 Inflation-Adjusted Dollars) \n",
    "  \"B17001_001E\": \"poverty_status_denominator\", # Poverty Status in the past 12 Months.\n",
    "  \"B17001_002E\": \"in_poverty\", # Income in the past 12 months below poverty level\n",
    "  \n",
    "  \"B08006_001E\": \"all_workers\", # Means of Transportation to Work - total population that works?\n",
    "  \"B08006_008E\": \"public_transit\", # Public transportation (excluding taxicab)\n",
    "  \"B08006_014E\": \"bike\", # Bicycle\n",
    "  \"B08006_015E\": \"walked\", # Walked\n",
    "\n",
    "\n",
    "  \"B12001_011E\": \"all_female_marital\", # Female Total - Sex by Marital Status for the Population 15 Years and over\n",
    "  \"B12001_013E\": \"female_married\", # Female:!!Now married\n",
    "\n",
    "  \"B25024_001E\": \"housing_units\", # Units in Structure (Housing Units?)\n",
    "  \"B25024_002E\": \"housing_units_single_detached\",\n",
    "  \"B25024_003E\": \"housing_units_single_attached\",\n",
    "}\n",
    "\n",
    "metadata = [\"state\", \"county\"]\n",
    "if unit == \"tract\": metadata += [\"tract\"]\n",
    "\n",
    "all_states = ['01', '02', '04', '05', '06', '08', '09', '10', '11', '12', '13', '15', '16',\n",
    "              '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29',\n",
    "              '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42',\n",
    "              '44', '45', '46', '47', '48', '49', '50', '51', '53', '54', '55', '56', '72']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with that out of the way, we define a function that loads the data for all tracts in a given state and attaches it to a FIPS code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_for_state(state):\n",
    "  # Load the data for all tracts in the given state, passed as a FIPS code.\n",
    "\n",
    "  try:\n",
    "  \t# Form the URL.\n",
    "    url = dataset + \"?key=%s&get=NAME,%s&for=%s&in=state:%s\" \\\n",
    "      % (api_key, \",\".join(fields), unit, state)\n",
    "\n",
    "    print(state + \"...\", file=sys.stderr)\n",
    "\n",
    "    # Make HTTP request and load JSON response.\n",
    "    data = json.load(io.TextIOWrapper(urllib.request.urlopen(url)))\n",
    "    header = data[0]\n",
    "    data = data[1:]\n",
    " \n",
    "    # Return as a list of dicts, e.g.:\n",
    "    # { 'state': '05', 'county': '145', 'tract': '070500', 'P0010001': '6300'}\n",
    "    for row in data:\n",
    "    \titem = dict(zip(header, row))\n",
    "    \tyield item\n",
    "\n",
    "  except Exception as e:\n",
    "  \traise Exception(\"Error %s loading tract data for state %s at %s.\" % (str(e), state, url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, finally we output the result to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loop over states, query the Census API for each state, and write stats to a CSV file.\n",
    "w = csv.writer(sys.stdout)\n",
    "cols = metadata + sorted(fields)\n",
    "w.writerow([fields.get(c, c) for c in cols])\n",
    "for state in all_states:\n",
    "  for tract in get_data_for_state(state):\n",
    "    w.writerow([tract.get(f) for f in cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we import the packages needed for computing pixels first. These are:\n",
    "* sys,\n",
    "* glob,\n",
    "* csv,\n",
    "* collections,\n",
    "* shapefile,\n",
    "* tqdm,\n",
    "* pyproj,\n",
    "* and PIL.\n",
    "These packages allow us to load in shapefile geography, define the coordinate system, and ultimately project to a raster to determine pixel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "import shapefile\n",
    "import tqdm\n",
    "import pyproj\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we declare variables needed prior to the actual projection to raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "\n",
    "unit = sys.argv[1] # \"tract\" or \"county\"\n",
    "width = int(sys.argv[2])\n",
    "\n",
    "##########################################\n",
    "\n",
    "contiguous_us = (\"01\", \"04\", \"05\", \"06\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"16\",\n",
    "\t             \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\",\n",
    "\t             \"28\", \"29\", \"30\", \"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\",\n",
    "\t             \"39\", \"40\", \"41\", \"42\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\",\n",
    "\t             \"51\", \"53\", \"54\", \"55\", \"56\", )\n",
    "\n",
    "# Define map projections (lat/lng and a nice one for contiguous US)\n",
    "p_latlng = pyproj.Proj(init='EPSG:4326')\n",
    "p_mapproj = pyproj.Proj(\"+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=clrk66 +units=m +no_defs\") # http://spatialreference.org/ref/sr-org/7271/\n",
    "\n",
    "# This is the bounding box of the projected map coordinates.\n",
    "projected_bounds = [(-2387000, 254700), (2263000, 3169000)]\n",
    "\n",
    "# Raster dimensions.\n",
    "height = int(round(width * (projected_bounds[1][1] - projected_bounds[0][1]) / (projected_bounds[1][0] - projected_bounds[0][0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define our helper function to project into map coordinates in [0,1]. Next, load the shapefiles so we can get a count of all shapes and store which geographic units occur in which pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to project into map coordinates in [0,1].\n",
    "def project(lng, lat):\n",
    "\t# Project.\n",
    "\tlng, lat = pyproj.transform(p_latlng, p_mapproj, lng, lat)\n",
    "\n",
    "\t# Scale to [0, 1].\n",
    "\tlng = (lng-projected_bounds[0][0]) / (projected_bounds[1][0] - projected_bounds[0][0])\n",
    "\tlat = (lat-projected_bounds[0][1]) / (projected_bounds[1][1] - projected_bounds[0][1])\n",
    "\n",
    "\treturn (lng, lat)\n",
    "\n",
    "# load shapefiles first so we can get a count of all shapes\n",
    "total_shapes = 0\n",
    "shapefiles = []\n",
    "for fn in glob.glob(\"shapefiles_%s/*.shp\" % unit):\n",
    "\tsf = shapefile.Reader(fn)\n",
    "\tshapefiles.append(sf)\n",
    "\ttotal_shapes += sf.numRecords\n",
    "\n",
    "# iterator over all files\n",
    "def iter_all_shapes():\n",
    "\tfor sf in shapefiles:\n",
    "\t\tfields = [f[0] for f in sf.fields[1:]]\n",
    "\t\tfor i, shape in enumerate(sf.iterShapes()):\n",
    "\t\t\t  # note: DeletionFlag is first in sf.fields but is not in sf.record(i)\n",
    "\t\t\tyield (sf, shape, dict(zip(fields, sf.record(i))))\n",
    "\n",
    "# Store which geographic units occur in which pixels.\n",
    "pixels = defaultdict(lambda : [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we draw combined map and by iterating though all the shapes we've loaded, count how many pixels are contained within each shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combined map.\n",
    "img_all = Image.new(\"L\", (width, height), 0)\n",
    "draw_all = ImageDraw.Draw(img_all)\n",
    "\n",
    "# iterate through all of the shapes\n",
    "for sf, shape, fields in \\\n",
    "\ttqdm.tqdm(iter_all_shapes(), total=total_shapes, file=sys.stderr, leave=True):\n",
    "\tassert shape.shapeType == 5\n",
    "\n",
    "\t# Because we're making a statement about how the units appears on a map,\n",
    "\t# project the lat/lng coordinates into a standard US map projection.\n",
    "\t# Skip the states that aren't in the contiguous U.S., since far-away\n",
    "\t# places will come out distorted in a projection meant for the contiguous\n",
    "\t# U.S.\n",
    "\tif fields[\"STATEFP\"] not in contiguous_us:\n",
    "\t\tcontinue\n",
    "\n",
    "\tgeo_id = fields[\"GEOID\"]\n",
    "\t# fields[\"ALAND\"] is land (excluding water) area as computed by the Census,\n",
    "\t# which is also interesting.\n",
    "\n",
    "\t# Project points to map coordinates.\n",
    "\tpolygon = shape.points\n",
    "\tpolygon = [project(lng, lat) for (lng, lat) in polygon]\n",
    "\n",
    "\t# Scale to image coordinates.\n",
    "\tpolygon = [(lng*width, height - lat*height) for (lng, lat) in polygon]\n",
    "\n",
    "\t# Create an empty greyscale image of a certain pixel size to rasterize the tract.\n",
    "\timg = Image.new(\"L\", (width, height), 0)\n",
    "\tdraw = ImageDraw.Draw(img)\n",
    "\n",
    "\t# Draw the shape.\n",
    "\tdraw.polygon(polygon, fill=255)\n",
    "\tdraw_all.polygon(polygon, fill=255)\n",
    "\n",
    "\t# We could count up the number of pixels that are now turned on\n",
    "\t# by calling img.histogram(), which is really fast. But because\n",
    "\t# at regular map resolutions some tracts will tend to fall on the same\n",
    "\t# pixels, we'll record which geographic units end up on which pixels.\n",
    "\t# img.getdata() returns a flat array of the pixels in raster order,\n",
    "\t# by row. By enumerating, each pixel gets a consistent integer identifier.\n",
    "\tis_drawn = False\n",
    "\tfor pixel, value in enumerate(img.getdata()):\n",
    "\t\tif value > 0: # really just 255 so long as there is no antialiasing\n",
    "\t\t\tif value != 255: raise Exception(\"encountered a pixel value that's not 0 or 255\")\n",
    "\t\t\tpixels[pixel].append(geo_id)\n",
    "\t\t\tis_drawn = True\n",
    "\n",
    "\tif not is_drawn:\n",
    "\t\t# Shape was too small to be represented in the raster image at all.\n",
    "\t\t# That means it's smaller than one pixel. All of the points on the\n",
    "\t\t# polygon will probably round to the same coordinate. But to be\n",
    "\t\t# sure, take the average of the coordinates and mark the shape\n",
    "\t\t# as being drawn at that one lump location.\n",
    "\t\tx = int(round(sum(latlng[0] for latlng in polygon)/len(polygon)))\n",
    "\t\ty = int(round(sum(latlng[1] for latlng in polygon)/len(polygon)))\n",
    "\t\tpixel = y*width + x\n",
    "\t\tpixels[pixel].append(geo_id)\n",
    "\n",
    "\t# Release object.\n",
    "\tdel draw\n",
    "\n",
    "# Save the image that has all of the shapes drawn, to verify that we're\n",
    "# drawing the right thing.\n",
    "del draw_all\n",
    "img_all.save(\"map_%s_%d.png\" % (unit, width), format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the pixel count for each shape, we again output to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write out each pixel that got lit up at all and the geographic unit IDs that did so.\n",
    "import csv\n",
    "w = csv.writer(sys.stdout)\n",
    "for pixel_id, geoid_list in sorted(pixels.items()):\n",
    "\tx = (pixel_id % width)\n",
    "\ty = pixel_id // width\n",
    "\tw.writerow([x, y] + geoid_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
